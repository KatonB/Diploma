Слайд 1
Добрый день уважаемые коллеги, меня зовут Чанчиков Антон Юрьевич. Я рад приветствовать вас сегодня и представляю результаты работы над ВКР по теме "Классификация изображений бинарными нейронными сетями с расширенной информацией".

Слайд 2
Мой доклад будет содержать следующие разделы: по тексту слайда.  В каждом разделе я постараюсь донести до вас основные идеи и результаты моей работы.
Начнем с введения.

Слайд 3
Сверточные нейронные сети - архитктура нейронных сетей, используемая для обработки изображений. Для выявления признаков из входных данных используются сверточный и субдискретизирующий оператор.

Слайд 4
Задача классификации изображений в компьютерном зрении заключается в определении вероятности принадлежности каждого изображения в некотором наборе данных к одному из классов. Количество классов определяется самим набором. В моей работе используется широкоприменяемый датасет CIFAR10.

Слайд 5
У нейронных сетей есть обучаемые параметры - веса, а также значения, которые мы подаем им на вход. Таких объектов при работе с моделями может быть сотни миллионов иил миллиардов и почти наверное/почти всегда, эти элементы являются числами с плавающей точкой, что сильно сказывается на требованиях к вычислительным ресурсам и требует больших затрат памяти.
Бинарные сети были предложены как варианты решения этих проблем. Идея заключается в том, чтобы все числа, с которыми работает сеть, преобразовать к двум значениям -1 и +1 по некоторому правилу (на слайде этим правилом является функция знака). Помимо очевидной экономии памяти на хранении, можно все операции с плавающей точкой в сверточных сетях заменить на простые логические операции XOR и Popcount, что уменьшит вычислительные затраты

Слайд 6
Помимо данных преимуществ, есть также недостатки, которые заключаются в том, что при бинаризации огромное количество информации теряется, что существенно ухудшает качество моделей.

Слайд 7
Цель и задачи по тексту слайда

Слайд 8
Масштабные исследования в области бинарных сетей начались не так давно, однако уже было предложено большое количество тактик по улучшению исходной идеи. Например, архитектура ReActNet предлагает (здесь по слайду), что позволяет подавать на вход сети подавать больше различной информации для анализа. Ir-Net для уменьшения эффекта потери информации при бинаризации весов предлагает (по слайду).

Слайд 9
Объединив два подхода и существенно их доработав, в 2022 году была представлена IE-Net или бинарная нейронная сеть с улучшенной информацией. Для бинаризации входных значений, как и в ReActNet, используется функция RSign, однако не одна для каждого изображения, а K штук, где K - настраиваемый гиперпараметр. Затем все эти выходные пакеты предлагагалось обрабатывать не по-отдельности, а все вместе путем создания обобщенной двочиной свертки, что сокращает вычислительные затраты.
Для бинаризации весов используется их стандартизация, как в IR-Net и функция специального вида IEE, постепенно аппроксимирующая знаковую, придавая градиентам весов ненулевые значения, что позволяет обучать сеть с использованием обратного распространения ошибки.

Слайд 10
На этом слайде я постарался в общих чертах собрать, что из себя в итоге представляет БНС с расширенной информацией.
*Рассказать про прямой и обратный ход*

Слайд 11
Для исследований БНС были выбраны такие популярные архитектуры нейронных сетей, как ResNet и MobileNetV2. 
ResNet - большая глубока сеть, требующая внушительных затрат по вычислениям и памяти, поэтому является перспективным кандидатом для бинаризации.
MobileNetV2 - высокоэффективная сеть, созданная для устройств с ограниченными ресурсами. Интересно проверить, как эффективную сеть получится оптимизировать еще сильнее.

Слайд 12
Помиом расширения информации я задался вопросом: можно ли результаты методов оптимизации полноточных сетей, такие как регуляризация, аугментация, дистилляция, прунин перенести на бинарные сети. А именно, если они хорошо себя показывают при работе с полноточными моделями, будут ли они также хороши после бинаризации? Переносятся ли результаты с небинарных сетей на бинарные? Об этом чуть дальше

Слайд 13
Исследовательский стенд по тексту слайда

Слайд 14
Перейдем к результатам
На слайде можно видеть три таблицы, первая показывает влияние расширения информации на нейронную сеть с точки зрения точности и времени обучения. Максимальная точность достигается при K=3, при этом время обучения на эпоху увеличивается чуть больше, чем в 3 раза, однако из второй таблицы можно заметить, что количество операций с плавающей точкой на порядок меньше полноточной сети, она легче в плане вычислений на видеокарте и требует меньше памяти для хранения. Связано это с тем, что БНС с расширенной информацией сложнее обычной нейронной сети в архитектурном плане и для ее обработки требуется больше времени, но выигрывает по памяти и вычислительным затратам.
Более того, теоретический выигрыш должен составлять примерно 1/32 от исходного, чего на практике не происходит из-за сложной технической реализации (можно видеть, что вес модели уменьшился примерно в 9 раз, а оперативной памяти ГПУ стала занимать меьнше в 1.27 раз). 
Третья таблица демонстрирует результаты эксперимента со стратегией обучения. Проводятся попытки поднять точность исходной модели (столбец 1) за счет методов регуляризации (столбец 2,3,5,6) и аугментации данных (столбец 4), а затем посмотреть на переносимость этих экспериментов на бинарную нейронную сеть с целью поиска зависимостей и выбора оптимальнго пути обучения. Первый столбец - точность обучения без каких-либо модификаций, а каждый следующий - добавление или удаление метода регуляризации относительно пердыдущего столбца. Например, третий столбец означает применение L2-регуляризации и сглаживания меток, а пятый - L2-рег, случайных преобразований без сглаживания меток.

Слайд 15
Эксперименты для MobileNetV2 проводились ровно те же самые, что и для ResNet18. Из интересного здесь можно отметить, что данная архитектура очень плохо поддается бинаризации и расширению информации (таблица 1), однако поиск оптимальной стратегии для полноточной модели был проведен и его результаты можно видеть в третьей таблице.

Слайд 16
Для ResNet18 был произведен процесс передачи знаний с полноточной предобученной сети на бинарный аналог при параметре K=3 с применением методов регуляризации в процессе дистилляции. При помощи данного процесса получилось поднять точность, которая не достигалась при обучении без учительской модели.

Слайд 17
Выводы по тексту слайда

Слайд 18
Заключение по тексту слайда

Слайд 19
Спасибо за внимание. Готов выслушать ваши вопросы.