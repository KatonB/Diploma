{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nia8Ca8MRKzN"
      },
      "source": [
        "# Либы"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Odi2Rt70kFTN",
        "outputId": "47b20a4a-5d7c-4d0c-e8e4-b833df2e37f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchprofile\n",
            "  Downloading torchprofile-0.0.4-py3-none-any.whl (7.7 kB)\n",
            "Requirement already satisfied: numpy>=1.14 in /usr/local/lib/python3.10/dist-packages (from torchprofile) (1.22.4)\n",
            "Requirement already satisfied: torch>=1.4 in /usr/local/lib/python3.10/dist-packages (from torchprofile) (2.0.1+cu118)\n",
            "Requirement already satisfied: torchvision>=0.4 in /usr/local/lib/python3.10/dist-packages (from torchprofile) (0.15.2+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->torchprofile) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->torchprofile) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->torchprofile) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->torchprofile) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->torchprofile) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->torchprofile) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.4->torchprofile) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.4->torchprofile) (16.0.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision>=0.4->torchprofile) (2.27.1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision>=0.4->torchprofile) (8.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.4->torchprofile) (2.1.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision>=0.4->torchprofile) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision>=0.4->torchprofile) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision>=0.4->torchprofile) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision>=0.4->torchprofile) (3.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.4->torchprofile) (1.3.0)\n",
            "Installing collected packages: torchprofile\n",
            "Successfully installed torchprofile-0.0.4\n"
          ]
        }
      ],
      "source": [
        "!pip install torchprofile\n",
        "#!pip install torchsummary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VB95IUiQCx32"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Function, Variable\n",
        "\n",
        "import math\n",
        "import numpy as np\n",
        "import torch.utils.model_zoo as model_zoo\n",
        "import torch.nn.init as init\n",
        "from scipy.stats import ortho_group\n",
        "\n",
        "import torch.utils\n",
        "import torch.utils.data\n",
        "from torchvision import datasets, transforms\n",
        "from torch.cuda.amp import autocast as autocast\n",
        "import torchvision.models as models\n",
        "import os, argparse, logging,sys\n",
        "import random\n",
        "import time\n",
        "import shutil\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.nn.parallel\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "import torch.nn.utils.prune as prune\n",
        "from sklearn.metrics import accuracy_score, recall_score, f1_score, roc_auc_score\n",
        "\n",
        "from torchsummary import summary\n",
        "from torchprofile import profile\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "\n",
        "\n",
        "device = torch.device('cuda:0')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wq4v_hVuFb0D"
      },
      "outputs": [],
      "source": [
        "random.seed(0)\n",
        "np.random.seed(0)\n",
        "torch.manual_seed(0)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(0)\n",
        "\n",
        "cudnn.deterministic = True\n",
        "cudnn.benchmark = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZGG4l8t0oCYi",
        "outputId": "89d6e3af-1bfd-4e7c-8166-8bc41ff59256"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F8K6qUWQS0By"
      },
      "source": [
        "# Utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YNp2ipwflX4V"
      },
      "outputs": [],
      "source": [
        "def top1_accuracy(targets, outputs):\n",
        "    outputs_tensor = torch.from_numpy(outputs)\n",
        "    targets_tensor = torch.from_numpy(targets)\n",
        "    _, predicted = torch.max(outputs_tensor, 1)\n",
        "    correct = torch.eq(predicted, targets_tensor).sum().item()\n",
        "    accuracy = correct / targets_tensor.size(0)\n",
        "    return accuracy\n",
        "\n",
        "def top5_accuracy(targets, outputs):\n",
        "    outputs_tensor = torch.from_numpy(outputs)\n",
        "    targets_tensor = torch.from_numpy(targets)\n",
        "    _, predicted = torch.topk(outputs_tensor, k=5, dim=1)\n",
        "    correct = torch.eq(predicted, targets_tensor.view(-1, 1)).sum().item()\n",
        "    accuracy = correct / targets_tensor.size(0)\n",
        "    return accuracy\n",
        "\n",
        "class StochasticDepth(nn.Module):\n",
        "    def __init__(self, p):\n",
        "        super(StochasticDepth, self).__init__()\n",
        "        self.p = p\n",
        "\n",
        "    def forward(self, x):\n",
        "        if not self.training:\n",
        "            return x\n",
        "        # if torch.rand(1).item() > self.p:\n",
        "        #     return x\n",
        "        # return torch.zeros_like(x)\n",
        "        if torch.rand(1).item() > self.p:\n",
        "            return x.clone().detach()\n",
        "        return torch.zeros_like(x).to(x.device)\n",
        "\n",
        "def custom_pruning(model):\n",
        "    if args.type_pruning == 'local':\n",
        "        #local prune. просто зануляем веса\n",
        "        for name, module in model.named_modules():\n",
        "            # prune 20% of connections in all 2D-conv layers\n",
        "            if isinstance(module, torch.nn.Conv2d):\n",
        "                prune.l1_unstructured(module, name='weight', amount=0.2)\n",
        "            # prune 40% of connections in all linear layers\n",
        "            elif isinstance(module, torch.nn.Linear):\n",
        "                prune.l1_unstructured(module, name='weight', amount=0.4)\n",
        "\n",
        "    elif args.type_pruning == 'global':\n",
        "\n",
        "        if args.architecture == 'cnn_model()' or args.bin_architecture == 'cnn_model_binary()':\n",
        "            parameters_to_prune = (\n",
        "                (model.conv1, 'weight'),\n",
        "                (model.conv2, 'weight'),\n",
        "                (model.conv3, 'weight'),\n",
        "                (model.conv4, 'weight'),\n",
        "                (model.fc1, 'weight'),\n",
        "                (model.fc2, 'weight'),\n",
        "            )\n",
        "\n",
        "            prune.global_unstructured(\n",
        "                parameters_to_prune,\n",
        "                pruning_method=prune.L1Unstructured,\n",
        "                amount=0.2,\n",
        "            )\n",
        "\n",
        "        elif args.architecture == 'resnet20()' or args.bin_architecture == 'resnet20_binary()':\n",
        "            return 0\n",
        "\n",
        "        else:\n",
        "            parameters_to_prune = [(module, \"weight\") for module in filter(lambda m: type(m) == torch.nn.Conv2d, model.modules())]\n",
        "            prune.global_unstructured(\n",
        "                parameters_to_prune,\n",
        "                pruning_method=prune.L1Unstructured,\n",
        "                amount=0.2,\n",
        "            )\n",
        "\n",
        "    else:\n",
        "      print('error')\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class LabelSmoothingCrossEntropyLoss(nn.Module):\n",
        "    def __init__(self, smoothing=0.0, num_classes=10):\n",
        "        super(LabelSmoothingCrossEntropyLoss, self).__init__()\n",
        "        self.smoothing = smoothing\n",
        "        self.num_classes = num_classes\n",
        "        self.confidence = 1.0 - smoothing\n",
        "\n",
        "        if smoothing > 0:\n",
        "            self.criterion = nn.KLDivLoss(reduction='batchmean')\n",
        "        else:\n",
        "            self.criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    def forward(self, pred, target):\n",
        "        one_hot = torch.full_like(pred, self.smoothing / (self.num_classes - 1))\n",
        "        one_hot.scatter_(1, target.unsqueeze(1).long(), self.confidence)\n",
        "\n",
        "        if self.smoothing > 0:\n",
        "            pred = pred.log_softmax(dim=1)\n",
        "\n",
        "        return self.criterion(pred, one_hot)\n",
        "\n",
        "def get_data():\n",
        "    if args.dataset == 'CIFAR10':\n",
        "        normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                    std=[0.229, 0.224, 0.225])\n",
        "\n",
        "        transform = transforms.Compose([\n",
        "            transforms.Resize(args.data_size),\n",
        "            # transforms.RandomHorizontalFlip(),\n",
        "            # transforms.RandomCrop(args.data_size, 4),\n",
        "            transforms.RandAugment(num_ops=args.rand_augment, magnitude=10),\n",
        "            transforms.ToTensor(),\n",
        "            normalize])\n",
        "\n",
        "    if args.dataset == 'MNIST':\n",
        "        normalize = transforms.Normalize(mean=[0.1307], std=[0.3081])\n",
        "\n",
        "        transform = transforms.Compose([\n",
        "            transforms.Resize(args.data_size),\n",
        "            transforms.RandAugment(num_ops=args.rand_augment, magnitude=10),\n",
        "            transforms.ToTensor(),\n",
        "            normalize\n",
        "        ])\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        eval('datasets.' + args.dataset + '(root=\"../\", train=True, transform=transform, download=True)'),\n",
        "        batch_size=args.batch_size, shuffle=True,\n",
        "        num_workers=args.workers)\n",
        "\n",
        "    val_loader = torch.utils.data.DataLoader(\n",
        "    eval('datasets.' + args.dataset + '(root=\"../\", train=False, transform=transforms.Compose([transforms.Resize(args.data_size),transforms.ToTensor(),normalize,]), download=True)'),\n",
        "    batch_size=args.batch_size, shuffle=False,\n",
        "    num_workers=args.workers)\n",
        "\n",
        "\n",
        "    return train_loader, val_loader\n",
        "\n",
        "\n",
        "\n",
        "def save_results(bin, args_list, train_loss_history, train_acc_history, train_recall_history, train_f1_history, train_top1_history, train_top5_history, valid_results, min_train_time, max_train_time, inf):\n",
        "\n",
        "    path_to_save = args.path_to_save\n",
        "    if not os.path.exists(path_to_save):\n",
        "        os.makedirs(path_to_save)\n",
        "\n",
        "    if bin == False:\n",
        "        path_to_file = 'ResultsNonBin.txt'\n",
        "    elif bin == True:\n",
        "        path_to_file = 'ResultsBin.txt'\n",
        "\n",
        "\n",
        "    with open(path_to_save + '/' + path_to_file, 'a') as file:\n",
        "        file.write('Общая информация о эксперименте \\n')\n",
        "        file.write(' || '.join([f'{arg}: {value}' for arg, value in args_list]))\n",
        "        file.write('\\n\\n{0}'.format(inf))\n",
        "        file.write('\\n\\nМинимальное и максимальное время на обучение эпохи в секунданх: {0} ; {1} \\n\\n'.format(min_train_time, max_train_time))\n",
        "        file.write('Epoch No.    Loss     Acc     Recall     F1     Top1     Top5 \\n')\n",
        "        for i in range(0, len(train_loss_history)):\n",
        "            if i<9:\n",
        "                file.write(f\"    {i+1}       {train_loss_history[i]}  {train_acc_history[i]}   {train_recall_history[i]}   {train_f1_history[i]}   {train_top1_history[i]}   {train_top5_history[i]}\\n\")\n",
        "            else:\n",
        "                file.write(f\"   {i+1}       {train_loss_history[i]}  {train_acc_history[i]}   {train_recall_history[i]}   {train_f1_history[i]}   {train_top1_history[i]}   {train_top5_history[i]}\\n\")\n",
        "        file.write('\\n  Valid     {0}  {1}   {2}   {3}   {4}   {5}\\n'.format(valid_results[0], valid_results[1], valid_results[2], valid_results[3], valid_results[4], valid_results[5]))\n",
        "        file.write('---------------------')\n",
        "        file.write('\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3oRDXABJRPSf"
      },
      "source": [
        "# Binary Modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "THO02boB7-GF"
      },
      "outputs": [],
      "source": [
        "def cpt_tk(epoch):\n",
        "    \"compute t&k in back-propagation\"\n",
        "    T_min, T_max = torch.tensor(1e-2).float(), torch.tensor(1e1).float()\n",
        "    Tmin, Tmax = torch.log10(T_min), torch.log10(T_max)\n",
        "    t = torch.tensor([torch.pow(torch.tensor(10.), Tmin + (Tmax - Tmin) / args.epochs * epoch)]).float()\n",
        "    k = max(1/t,torch.tensor(1.)).float()\n",
        "    return t, k"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FONOKt84C3p8"
      },
      "outputs": [],
      "source": [
        "#-----------------------IEE------------------------------------------\n",
        "class OwnQuantize_a(Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, input, k, t):\n",
        "        ctx.save_for_backward(input, k, t)\n",
        "        out = torch.sign(input)\n",
        "        return out\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        input, k, t = ctx.saved_tensors\n",
        "        k = torch.tensor(1.).to(input.device)\n",
        "        t = max(t, torch.tensor(1.).to(input.device))\n",
        "        # grad_input = k * (1.4*t - torch.abs(t**2 * input))\n",
        "        grad_input = k * (3*torch.sqrt(t**2/3) - torch.abs(t ** 2 * input*3)/2)\n",
        "        grad_input = grad_input.clamp(min=0) * grad_output.clone()\n",
        "        return grad_input, None, None\n",
        "class OwnQuantize(Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, input, k, t):\n",
        "        ctx.save_for_backward(input, k, t)\n",
        "        out = torch.sign(input)\n",
        "        return out\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        input, k, t = ctx.saved_tensors\n",
        "        # grad_input = k * (1.4*t - torch.abs(t**2 * input))\n",
        "        grad_input = k * (3*torch.sqrt(t**2/3) - torch.abs(t ** 2 * input*3)/2)\n",
        "        grad_input = grad_input.clamp(min=0) * grad_output.clone()\n",
        "        return grad_input, None, None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "74vj-paOC6uT"
      },
      "outputs": [],
      "source": [
        "class BinarizeConv2d(nn.Conv2d):\n",
        "\n",
        "    def __init__(self, *kargs, **kwargs):\n",
        "        super(BinarizeConv2d, self).__init__(*kargs, **kwargs)\n",
        "        self.k = torch.tensor([10.]).float()\n",
        "        self.t = torch.tensor([0.1]).float()\n",
        "\n",
        "        w = self.weight\n",
        "\n",
        "        sw = w.abs().view(w.size(0), -1).mean(-1).float().view(w.size(0), 1, 1).detach()\n",
        "        self.alpha = nn.Parameter(sw.to(device), requires_grad=True)\n",
        "\n",
        "    def forward(self, input):\n",
        "        a = input\n",
        "        w = self.weight\n",
        "        w0 = w - w.mean([1, 2, 3], keepdim=True)\n",
        "        w1 = w0 / torch.sqrt(w0.var([1, 2, 3], keepdim=True) + 1e-5)\n",
        "        if self.training:\n",
        "            a0 = a / torch.sqrt(a.var([1, 2, 3], keepdim=True) + 1e-5)\n",
        "        else:\n",
        "            a0 = a\n",
        "\n",
        "        #* binarize\n",
        "        bw = OwnQuantize().apply(w1,self.k.to(w.device),self.t.to(w.device))\n",
        "\n",
        "        ba = OwnQuantize_a().apply(a0,self.k.to(w.device),self.t.to(w.device))\n",
        "\n",
        "        #* 1bit conv\n",
        "        output = F.conv2d(ba, bw, self.bias, self.stride, self.padding,\n",
        "                          self.dilation, self.groups)\n",
        "        #* scaling factor\n",
        "        output = output * self.alpha\n",
        "        return output\n",
        "\n",
        "class channel_w(nn.Module):\n",
        "    def __init__(self,p):\n",
        "        super(channel_w, self).__init__()\n",
        "        self.w1 = torch.nn.Parameter(torch.rand(1)*0.001, requires_grad=True)\n",
        "\n",
        "    def forward(self,x):\n",
        "        output = self.w1 * x\n",
        "        return output\n",
        "# class OwnBinaryConv(nn.Module):\n",
        "#     def __init__(self,in_ch,out_ch,kernel_size=3,stride=1,padding=1):\n",
        "#         super(OwnBinaryConv, self).__init__()\n",
        "#         self.shift1 = nn.Parameter(torch.zeros(1,in_ch,1,1), requires_grad=True)\n",
        "#         self.shift2 = nn.Parameter(torch.zeros(1, in_ch, 1, 1), requires_grad=True)\n",
        "#         self.conv = BinarizeConv2d(in_ch,out_ch,kernel_size=kernel_size,stride=stride,padding=padding)\n",
        "#         self.scale = channel_w(out_ch)\n",
        "\n",
        "#     def forward(self,x):\n",
        "#         x1 = x + self.shift1.expand_as(x)\n",
        "#         x2 = x + self.shift2.expand_as(x)\n",
        "\n",
        "#         out1 = self.conv(x1)\n",
        "#         out2 = self.conv(x2)\n",
        "\n",
        "#         out = out1+self.scale(out2)\n",
        "\n",
        "#         return out\n",
        "\n",
        "class OwnBinaryConv(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch, kernel_size=3, stride=1, padding=1, groups=1, bias = False):\n",
        "        super(OwnBinaryConv, self).__init__()\n",
        "        self.K = args.K\n",
        "        self.shifts = nn.ParameterList([nn.Parameter(torch.zeros(1, in_ch, 1, 1), requires_grad=True) for _ in range(self.K)])\n",
        "        self.conv = BinarizeConv2d(in_ch, out_ch, kernel_size=kernel_size, stride=stride, padding=padding, groups=groups, bias=bias)\n",
        "        self.scale = channel_w(out_ch)\n",
        "        self.weight = self.conv.weight\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = None\n",
        "        for i in range(self.K):\n",
        "            xi = x + self.shifts[i].expand_as(x)\n",
        "            outi = self.conv(xi)\n",
        "            if out is None:\n",
        "                out = outi\n",
        "            else:\n",
        "                out = out + self.scale(outi)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j6Vchr9r8VdT"
      },
      "source": [
        "# Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jnmwHrOMdRiB"
      },
      "source": [
        "## Бинаризация архитектур"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DNcC521SdBIL"
      },
      "outputs": [],
      "source": [
        "def replace_conv2d(module, conv):\n",
        "    for name, child in module.named_children():\n",
        "        if isinstance(child, nn.Conv2d):\n",
        "            conv_str = f\"({child.in_channels}, {child.out_channels}, kernel_size={child.kernel_size}, stride={child.stride}, padding={child.padding})\"\n",
        "            module.__setattr__(name, eval(conv + conv_str))\n",
        "        else:\n",
        "            replace_conv2d(child, conv)\n",
        "\n",
        "def replace_relu(module):\n",
        "    for name, child in module.named_children():\n",
        "        if isinstance(child, nn.ReLU):\n",
        "            relu_str = f\"(inplace={child.inplace})\"\n",
        "            module.__setattr__(name, eval(\"nn.Hardtanh\" + relu_str))\n",
        "        else:\n",
        "            replace_relu(child)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZ-D7JdPXsNb"
      },
      "source": [
        "## ResNet18\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hrAIe1s9Xt9u"
      },
      "outputs": [],
      "source": [
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        if args.binary == False:\n",
        "            self.cv1 = 'nn.Conv2d'\n",
        "            self.cv2 = 'nn.Conv2d'\n",
        "            self.activat = 'F.relu'\n",
        "        elif args.binary == True:\n",
        "            self.cv1 = 'OwnBinaryConv'\n",
        "            self.cv2 = 'BinarizeConv2d'\n",
        "            self.activat = 'F.hardtanh'\n",
        "\n",
        "        self.conv1 = eval(self.cv1 + '(in_planes, planes, kernel_size=3, stride=stride, padding=1)')\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = eval(self.cv1 + '(planes, planes, kernel_size=3, stride=1, padding=1)')\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                eval(self.cv2 + '(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False)'),\n",
        "                nn.BatchNorm2d(self.expansion*planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = eval(self.activat + '(self.bn1(self.conv1(x)))')\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = eval(self.activat + '(out)')\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, num_blocks, num_channel, num_classes=10):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_planes = num_channel[0]\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, num_channel[0], kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(num_channel[0])\n",
        "        self.layer1 = self._make_layer(block, num_channel[0], num_blocks[0], stride=1)\n",
        "        self.layer2 = self._make_layer(block, num_channel[1], num_blocks[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, num_channel[2], num_blocks[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, num_channel[3], num_blocks[3], stride=2)\n",
        "        self.linear = nn.Linear(num_channel[3]*block.expansion, num_classes)\n",
        "        self.bn2 = nn.BatchNorm1d(num_channel[3]*block.expansion)\n",
        "\n",
        "        self.prob = args.dropout\n",
        "        self.dropout = nn.Dropout(p=self.prob)\n",
        "\n",
        "    def _make_layer(self, block, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1]*(num_blocks-1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_planes, planes, stride))\n",
        "            self.in_planes = planes * block.expansion\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.bn1(self.conv1(x))\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = F.avg_pool2d(out, 4)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.bn2(out)\n",
        "        out = self.dropout(out)\n",
        "        out = self.linear(out)\n",
        "        return out\n",
        "\n",
        "def resnet18(**kwargs):\n",
        "    return ResNet(BasicBlock, [2,2,2,2],[64,128,256,512],**kwargs)\n",
        "# def resnet18_binary(**kwargs):\n",
        "#     return ResNet(BasicBlock, [2,2,2,2],[64,128,256,512],**kwargs)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0isRO-GJbW0d"
      },
      "source": [
        "## MobileNetV2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OzzqyPCqbWFU"
      },
      "outputs": [],
      "source": [
        "# class MobileNetV2(nn.Module):\n",
        "#     def __init__(self, num_classes=10):\n",
        "#         super(MobileNetV2, self).__init__()\n",
        "#         self.features = nn.Sequential(\n",
        "#             nn.Conv2d(3, 32, kernel_size=3, stride=2, padding=1, bias=False),\n",
        "#             nn.BatchNorm2d(32),\n",
        "#             nn.ReLU(inplace=True),\n",
        "#             nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1, groups=32, bias=False),\n",
        "#             nn.BatchNorm2d(32),\n",
        "#             nn.ReLU(inplace=True),\n",
        "#             nn.Conv2d(32, 64, kernel_size=1, stride=1, padding=0, bias=False),\n",
        "#             nn.BatchNorm2d(64),\n",
        "#             nn.ReLU(inplace=True),\n",
        "#             nn.Conv2d(64, 64, kernel_size=3, stride=2, padding=1, groups=64, bias=False),\n",
        "#             nn.BatchNorm2d(64),\n",
        "#             nn.ReLU(inplace=True),\n",
        "#             nn.Conv2d(64, 128, kernel_size=1, stride=1, padding=0, bias=False),\n",
        "#             nn.BatchNorm2d(128),\n",
        "#             nn.ReLU(inplace=True),\n",
        "#             nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1, groups=128, bias=False),\n",
        "#             nn.BatchNorm2d(128),\n",
        "#             nn.ReLU(inplace=True),\n",
        "#             nn.Conv2d(128, 128, kernel_size=1, stride=1, padding=0, bias=False),\n",
        "#             nn.BatchNorm2d(128),\n",
        "#             nn.ReLU(inplace=True),\n",
        "#             nn.Conv2d(128, 256, kernel_size=3, stride=2, padding=1, groups=128, bias=False),\n",
        "#             nn.BatchNorm2d(256),\n",
        "#             nn.ReLU(inplace=True),\n",
        "#             nn.Conv2d(256, 256, kernel_size=1, stride=1, padding=0, bias=False),\n",
        "#             nn.BatchNorm2d(256),\n",
        "#             nn.ReLU(inplace=True),\n",
        "#             nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1, groups=256, bias=False),\n",
        "#             nn.BatchNorm2d(256),\n",
        "#             nn.ReLU(inplace=True),\n",
        "#             nn.Conv2d(256, 512, kernel_size=1, stride=1, padding=0, bias=False),\n",
        "#             nn.BatchNorm2d(512),\n",
        "#             nn.ReLU(inplace=True),\n",
        "#             nn.Conv2d(512, 512, kernel_size=3, stride=2, padding=1, groups=512, bias=False),\n",
        "#             nn.BatchNorm2d(512),\n",
        "#             nn.ReLU(inplace=True),\n",
        "#             nn.Conv2d(512, 512, kernel_size=1, stride=1, padding=0, bias=False),\n",
        "#             nn.BatchNorm2d(512),\n",
        "#             nn.ReLU(inplace=True),\n",
        "#             nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1, groups=512, bias=False),\n",
        "#             nn.BatchNorm2d(512),\n",
        "#             nn.ReLU(inplace=True),\n",
        "#             nn.Conv2d(512, 512, kernel_size=1, stride=1, padding=0, bias=False),\n",
        "#             nn.BatchNorm2d(512),\n",
        "#             nn.ReLU(inplace=True),\n",
        "#             nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1, groups=512, bias=False),\n",
        "#             nn.BatchNorm2d(512),\n",
        "#             nn.ReLU(inplace=True),\n",
        "#             nn.Conv2d(512, 512, kernel_size=1, stride=1, padding=0, bias=False),\n",
        "#             nn.BatchNorm2d(512),\n",
        "#             nn.ReLU(inplace=True),\n",
        "#             nn.Conv2d(512, 512, kernel_size=3, stride=2, padding=1, groups=512, bias=False),\n",
        "#             nn.BatchNorm2d(512),\n",
        "#             nn.ReLU(inplace=True),\n",
        "#             nn.Conv2d(512, 512, kernel_size=1, stride=1, padding=0, bias=False),\n",
        "#             nn.BatchNorm2d(512),\n",
        "#             nn.ReLU(inplace=True),\n",
        "#             nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1, groups=512, bias=False),\n",
        "#             nn.BatchNorm2d(512),\n",
        "#             nn.ReLU(inplace=True),\n",
        "#             nn.Conv2d(512, 512, kernel_size=1, stride=1, padding=0, bias=False),\n",
        "#             nn.BatchNorm2d(512),\n",
        "#             nn.ReLU(inplace=True),\n",
        "#             nn.AdaptiveAvgPool2d(1)\n",
        "#         )\n",
        "#         self.classifier = nn.Sequential(\n",
        "#             nn.Dropout(args.dropout),\n",
        "#             nn.Linear(512, num_classes)\n",
        "#         )\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         x = self.features(x)\n",
        "#         x = x.view(x.size(0), -1)\n",
        "#         x = self.classifier(x)\n",
        "#         return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4dbIIEt6cLPC"
      },
      "outputs": [],
      "source": [
        "# def replace_conv2d(module, conv):\n",
        "#     for name, child in module.named_children():\n",
        "#         if isinstance(child, nn.Conv2d):\n",
        "#             conv_str = f\"({child.in_channels}, {child.out_channels}, kernel_size={child.kernel_size}, stride={child.stride}, padding={child.padding})\"\n",
        "#             module.__setattr__(name, eval(conv + conv_str))\n",
        "#         else:\n",
        "#             replace_conv2d(child, conv)\n",
        "#         if isinstance(child, nn.Sequential):\n",
        "#             for sub_name, sub_child in child.named_children():\n",
        "#                 if isinstance(sub_child, nn.Conv2d):\n",
        "#                     conv_str = f\"({sub_child.in_channels}, {sub_child.out_channels}, kernel_size={sub_child.kernel_size}, stride={sub_child.stride}, padding={sub_child.padding})\"\n",
        "#                     child.__setattr__(sub_name, eval(conv + conv_str))\n",
        "#                 else:\n",
        "#                     replace_conv2d(sub_child, conv)\n",
        "\n",
        "# def replace_relu(module):\n",
        "#     for name, child in module.named_children():\n",
        "#         if isinstance(child, nn.ReLU):\n",
        "#             relu_str = f\"(inplace={child.inplace})\"\n",
        "#             module.__setattr__(name, eval(\"nn.Hardtanh\" + relu_str))\n",
        "#         else:\n",
        "#             replace_relu(child)\n",
        "#         if isinstance(child, nn.Sequential):\n",
        "#             for sub_name, sub_child in child.named_children():\n",
        "#                 if isinstance(sub_child, nn.ReLU):\n",
        "#                     relu_str = f\"(inplace={sub_child.inplace})\"\n",
        "#                     child.__setattr__(sub_name, eval(\"nn.Hardtanh\" + relu_str))\n",
        "#                 else:\n",
        "#                     replace_relu(sub_child)\n",
        "\n",
        "\n",
        "# def conv_dw(in_channels, out_channels, stride):\n",
        "#     return nn.Sequential(\n",
        "#         nn.Conv2d(in_channels, in_channels, kernel_size=3, stride=stride, padding=1, groups=in_channels, bias=False),\n",
        "#         nn.BatchNorm2d(in_channels),\n",
        "#         nn.ReLU(inplace=True),\n",
        "#         nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0, bias=False),\n",
        "#         nn.BatchNorm2d(out_channels),\n",
        "#         nn.ReLU(inplace=True)\n",
        "#     )\n",
        "\n",
        "# class MobileNetV2(nn.Module):\n",
        "#     def __init__(self, num_classes=10):\n",
        "#         super(MobileNetV2, self).__init__()\n",
        "#         self.in_channels = 32\n",
        "\n",
        "#         self.features = nn.Sequential(\n",
        "#             nn.Conv2d(3, self.in_channels, kernel_size=3, stride=2, padding=1, bias=False),\n",
        "#             nn.BatchNorm2d(self.in_channels),\n",
        "#             nn.ReLU(inplace=True),\n",
        "\n",
        "#             conv_dw(self.in_channels, 64, stride=1),\n",
        "#             conv_dw(64, 128, stride=2),\n",
        "#             conv_dw(128, 128, stride=1),\n",
        "#             conv_dw(128, 256, stride=2),\n",
        "#             conv_dw(256, 256, stride=1),\n",
        "#             conv_dw(256, 512, stride=2),\n",
        "\n",
        "#             nn.Sequential(\n",
        "#                 *[conv_dw(512, 512, stride=1) for _ in range(5)]\n",
        "#             ),\n",
        "\n",
        "#             conv_dw(512, 1024, stride=2),\n",
        "#             conv_dw(1024, 1024, stride=1)\n",
        "#         )\n",
        "\n",
        "#         self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
        "#         self.classifier = nn.Linear(1024, num_classes)\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         x = self.features(x)\n",
        "#         x = self.avgpool(x)\n",
        "#         x = x.view(x.size(0), -1)\n",
        "#         x = self.classifier(x)\n",
        "#         return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BjciPqGom0E1"
      },
      "outputs": [],
      "source": [
        "\n",
        "# # Определение блока сверточных слоев в MobileNetV2\n",
        "# def conv_bn(in_channels, out_channels, stride):\n",
        "#     return nn.Sequential(\n",
        "#         nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False),\n",
        "#         nn.BatchNorm2d(out_channels),\n",
        "#         nn.ReLU(inplace=True)\n",
        "#     )\n",
        "\n",
        "# # Определение блока Bottleneck в MobileNetV2\n",
        "# class Bottleneck(nn.Module):\n",
        "#     def __init__(self, in_channels, out_channels, stride, expansion):\n",
        "#         super(Bottleneck, self).__init__()\n",
        "#         self.stride = stride\n",
        "#         mid_channels = in_channels * expansion\n",
        "\n",
        "#         self.conv1 = nn.Conv2d(in_channels, mid_channels, kernel_size=1, stride=1, padding=0, bias=False)\n",
        "#         self.bn1 = nn.BatchNorm2d(mid_channels)\n",
        "\n",
        "#         self.conv2 = nn.Conv2d(mid_channels, mid_channels, kernel_size=3, stride=stride, padding=1, groups=mid_channels, bias=False)\n",
        "#         self.bn2 = nn.BatchNorm2d(mid_channels)\n",
        "\n",
        "#         self.conv3 = nn.Conv2d(mid_channels, out_channels, kernel_size=1, stride=1, padding=0, bias=False)\n",
        "#         self.bn3 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "#         self.relu = nn.ReLU(inplace=True)\n",
        "#         self.shortcut = nn.Sequential()\n",
        "#         if stride == 1 and in_channels != out_channels:\n",
        "#             self.shortcut = nn.Sequential(\n",
        "#                 nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0, bias=False),\n",
        "#                 nn.BatchNorm2d(out_channels)\n",
        "#             )\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         identity = x\n",
        "\n",
        "#         out = self.conv1(x)\n",
        "#         out = self.bn1(out)\n",
        "#         out = self.relu(out)\n",
        "\n",
        "#         out = self.conv2(out)\n",
        "#         out = self.bn2(out)\n",
        "#         out = self.relu(out)\n",
        "\n",
        "#         out = self.conv3(out)\n",
        "#         out = self.bn3(out)\n",
        "\n",
        "#         out += self.shortcut(identity)\n",
        "#         out = self.relu(out)\n",
        "\n",
        "#         return out\n",
        "\n",
        "# # Определение архитектуры MobileNetV2\n",
        "# class MobileNetV2(nn.Module):\n",
        "#     def __init__(self, num_classes=10):\n",
        "#         super(MobileNetV2, self).__init__()\n",
        "\n",
        "#         self.features = nn.Sequential(\n",
        "#             conv_bn(3, 32, stride=2),\n",
        "#             Bottleneck(32, 16, stride=1, expansion=1),\n",
        "\n",
        "#             Bottleneck(16, 24, stride=2, expansion=6),\n",
        "#             Bottleneck(24, 24, stride=1, expansion=6),\n",
        "\n",
        "#             Bottleneck(24, 32, stride=2, expansion=6),\n",
        "#             Bottleneck(32, 32, stride=1, expansion=6),\n",
        "#             Bottleneck(32, 32, stride=1, expansion=6),\n",
        "\n",
        "#             Bottleneck(32, 64, stride=2, expansion=6),\n",
        "#             Bottleneck(64, 64, stride=1, expansion=6),\n",
        "#             Bottleneck(64, 64, stride=1, expansion=6),\n",
        "#             Bottleneck(64, 64, stride=1, expansion=6),\n",
        "\n",
        "#             Bottleneck(64, 96, stride=1, expansion=6),\n",
        "#             Bottleneck(96, 96, stride=1, expansion=6),\n",
        "#             Bottleneck(96, 96, stride=1, expansion=6),\n",
        "\n",
        "#             Bottleneck(96, 160, stride=2, expansion=6),\n",
        "#             Bottleneck(160, 160, stride=1, expansion=6),\n",
        "#             Bottleneck(160, 160, stride=1, expansion=6),\n",
        "\n",
        "#             Bottleneck(160, 320, stride=1, expansion=6),\n",
        "#         )\n",
        "\n",
        "#         self.conv1 = conv_bn(320, 1280, stride=1)\n",
        "#         self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
        "#         self.classifier = nn.Linear(1280, num_classes)\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         x = self.features(x)\n",
        "#         x = self.conv1(x)\n",
        "#         x = self.avgpool(x)\n",
        "#         x = x.view(x.size(0), -1)\n",
        "#         x = self.classifier(x)\n",
        "#         return x\n",
        "\n",
        "# # Создание экземпляра модели MobileNetV2\n",
        "# model = MobileNetV2()\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "def conv_bn(in_channels, out_channels, stride):\n",
        "    return nn.Sequential(\n",
        "        nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False),\n",
        "        nn.BatchNorm2d(out_channels),\n",
        "        nn.ReLU(inplace=True)\n",
        "    )\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, stride, expansion):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        self.stride = stride\n",
        "        mid_channels = in_channels * expansion\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels, mid_channels, kernel_size=1, stride=1, padding=0, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(mid_channels)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(mid_channels, mid_channels, kernel_size=3, stride=stride, padding=1, groups=mid_channels, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(mid_channels)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(mid_channels, out_channels, kernel_size=1, stride=1, padding=0, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride == 1 and in_channels != out_channels:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0, bias=False),\n",
        "                nn.BatchNorm2d(out_channels)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv3(out)\n",
        "        out = self.bn3(out)\n",
        "\n",
        "        if self.stride == 1:\n",
        "            out += self.shortcut(identity)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class MobileNetV2(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(MobileNetV2, self).__init__()\n",
        "\n",
        "        self.features = nn.Sequential(\n",
        "            conv_bn(3, 32, stride=1),\n",
        "            Bottleneck(32, 16, stride=1, expansion=1),\n",
        "\n",
        "            Bottleneck(16, 24, stride=1, expansion=6),\n",
        "            Bottleneck(24, 24, stride=1, expansion=6),\n",
        "\n",
        "            Bottleneck(24, 32, stride=2, expansion=6),\n",
        "            Bottleneck(32, 32, stride=1, expansion=6),\n",
        "            Bottleneck(32, 32, stride=1, expansion=6),\n",
        "\n",
        "            Bottleneck(32, 64, stride=2, expansion=6),\n",
        "            Bottleneck(64, 64, stride=1, expansion=6),\n",
        "            Bottleneck(64, 64, stride=1, expansion=6),\n",
        "            Bottleneck(64, 64, stride=1, expansion=6),\n",
        "\n",
        "            Bottleneck(64, 96, stride=1, expansion=6),\n",
        "            Bottleneck(96, 96, stride=1, expansion=6),\n",
        "            Bottleneck(96, 96, stride=1, expansion=6),\n",
        "\n",
        "            Bottleneck(96, 160, stride=2, expansion=6),\n",
        "            Bottleneck(160, 160, stride=1, expansion=6),\n",
        "            Bottleneck(160, 160, stride=1, expansion=6),\n",
        "\n",
        "            Bottleneck(160, 320, stride=1, expansion=6),\n",
        "        )\n",
        "\n",
        "        self.conv1 = conv_bn(320, 1280, stride=1)\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.dropout = nn.Dropout(p=args.dropout)\n",
        "        self.classifier = nn.Linear(1280, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.conv1(x)\n",
        "        x = self.avgpool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.dropout(x)\n",
        "        x = self.classifier(x)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8n0p54rAbnrU"
      },
      "outputs": [],
      "source": [
        "def mobilenetv2():\n",
        "    if args.binary == False:\n",
        "        return MobileNetV2()\n",
        "        # model = models.mobilenet_v2(pretrained=False)\n",
        "        # num_classes = 10\n",
        "        # model.classifier[1] = torch.nn.Linear(1280, num_classes)\n",
        "        # return model\n",
        "\n",
        "    elif args.binary == True:\n",
        "        model = MobileNetV2()\n",
        "        replace_conv2d(model, 'OwnBinaryConv')\n",
        "        replace_relu(model)\n",
        "        return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fVIAImitn3y5"
      },
      "outputs": [],
      "source": [
        "# print(args.binary)\n",
        "# print(mobilenetv2())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eRvXwB6_TBmf"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GlShptRTTDK6"
      },
      "outputs": [],
      "source": [
        "def train(model, train_loader, loss_f, optimizer, epoch):\n",
        "    model.train()\n",
        "    preds_all = []\n",
        "    targets_all = []\n",
        "\n",
        "    if args.pruning == True and epoch == int(args.epochs/2):\n",
        "      custom_pruning(model)\n",
        "\n",
        "\n",
        "    for i, (input, target) in enumerate(train_loader):\n",
        "\n",
        "        target = target.to(device)\n",
        "        input_var = input.to(device)\n",
        "        target_var = target.to(device)\n",
        "\n",
        "        # compute output\n",
        "        preds = model(input_var)\n",
        "\n",
        "        loss = loss_f(preds, target_var)\n",
        "\n",
        "        # use this loss for any training statistics\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "        preds = preds.float()\n",
        "        loss = loss.float()\n",
        "        preds_all.append(torch.softmax(preds.detach(), dim=1).cpu().numpy())\n",
        "        targets_all.append(target.cpu().numpy())\n",
        "\n",
        "        # measure accuracy, recall, f1-score, auc and record loss\n",
        "        # y_true = target.cpu().numpy()\n",
        "        # y_pred = preds.cpu().argmax(axis=1).numpy()\n",
        "        # acc = accuracy_score(y_true, y_pred)\n",
        "        # recall = recall_score(y_true, y_pred)\n",
        "        # f1 = f1_score(y_true, y_pred)\n",
        "        #auc = roc_auc_score(y_true, preds[:, 1].detach().cpu().numpy(), multi_class='ovr')\n",
        "\n",
        "    # recall_history.append(recall)\n",
        "    # f1_history.append(f1)\n",
        "    # #auc_history.append(auc)\n",
        "    # loss_history.append(loss)\n",
        "    # accuracy_history.append(acc)\n",
        "\n",
        "    # concatenate predictions and targets for all batches\n",
        "    preds_all = np.concatenate(preds_all, axis=0)\n",
        "    targets_all = np.concatenate(targets_all, axis=0)\n",
        "\n",
        "    # calculate metrics for all data\n",
        "    loss = '{:.4f}'.format(loss.item())\n",
        "    acc_all = '{:.4f}'.format(accuracy_score(targets_all, preds_all.argmax(axis=1)).item())\n",
        "    recall_all = '{:.4f}'.format(recall_score(targets_all, preds_all.argmax(axis=1), average ='macro').item())\n",
        "    f1_all = '{:.4f}'.format(f1_score(targets_all, preds_all.argmax(axis=1), average ='macro').item())\n",
        "    top1_all = '{:.4f}'.format(top1_accuracy(targets_all, preds_all))\n",
        "    top5_all = '{:.4f}'.format(top1_accuracy(targets_all, preds_all))\n",
        "\n",
        "    #auc_all = roc_auc_score(targets_all, preds_all[:, 1])\n",
        "\n",
        "    #return loss_history, accuracy_history, recall_history, f1_history, recall_all, f1_all\n",
        "    return loss, acc_all, recall_all, f1_all, top1_all, top5_all"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x3_maKujrEmM"
      },
      "source": [
        "# Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y4HfjRL_rJ89"
      },
      "outputs": [],
      "source": [
        "def validate(model, val_loader, loss_f):\n",
        "    model.eval()\n",
        "    preds_all = []\n",
        "    targets_all = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (input, target) in enumerate(val_loader):\n",
        "            target = target.to(device)\n",
        "            input_var = input.to(device)\n",
        "            target_var = target.to(device)\n",
        "\n",
        "            preds = model(input_var)\n",
        "            loss = loss_f(preds, target_var)\n",
        "\n",
        "            preds = preds.float()\n",
        "            loss = loss.float()\n",
        "            preds_all.append(torch.softmax(preds.detach(), dim=1).cpu().numpy())\n",
        "            targets_all.append(target.cpu().numpy())\n",
        "\n",
        "            # measure accuracy, recall, f1-score, auc and record loss\n",
        "            # y_true = target.cpu().numpy()\n",
        "            # y_pred = preds.cpu().argmax(axis=1).numpy()\n",
        "            # acc = accuracy_score(y_true, y_pred)\n",
        "            # recall = recall_score(y_true, y_pred, average='macro')\n",
        "            # f1 = f1_score(y_true, y_pred, average='macro')\n",
        "            #auc = roc_auc_score(y_true, preds[:, 1].detach().cpu().numpy(), multi_class='ovr')\n",
        "\n",
        "    # recall_history.append(recall)\n",
        "    # f1_history.append(f1)\n",
        "    # #auc_history.append(auc)\n",
        "    # loss_history.append(loss)\n",
        "    # accuracy_history.append(acc)\n",
        "\n",
        "    # concatenate predictions and targets for all batches\n",
        "    preds_all = np.concatenate(preds_all, axis=0)\n",
        "    targets_all = np.concatenate(targets_all, axis=0)\n",
        "\n",
        "    # calculate metrics for all data\n",
        "    loss = '{:.4f}'.format(loss.item())\n",
        "    acc_all = '{:.4f}'.format(accuracy_score(targets_all, preds_all.argmax(axis=1)).item())\n",
        "    recall_all = '{:.4f}'.format(recall_score(targets_all, preds_all.argmax(axis=1), average ='macro').item())\n",
        "    f1_all = '{:.4f}'.format(f1_score(targets_all, preds_all.argmax(axis=1), average ='macro').item())\n",
        "    top1_all = '{:.4f}'.format(top1_accuracy(targets_all, preds_all))\n",
        "    top5_all = '{:.4f}'.format(top1_accuracy(targets_all, preds_all))\n",
        "    #auc_all = roc_auc_score(targets_all, preds_all[:, 1])\n",
        "\n",
        "    return loss, acc_all, recall_all, f1_all, top1_all, top5_all"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V8V_ix_oEM7n"
      },
      "source": [
        "# Дистилляция"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x4bP4UstLakz"
      },
      "outputs": [],
      "source": [
        "def distill(teacher_outputs, student_outputs, temperature):\n",
        "    teacher_softmax = nn.functional.softmax(teacher_outputs / temperature, dim=1)\n",
        "    student_softmax = nn.functional.softmax(student_outputs / temperature, dim=1)\n",
        "    return nn.KLDivLoss(reduction='batchmean')(nn.LogSoftmax()(student_outputs / temperature), teacher_softmax)\n",
        "\n",
        "\n",
        "def destill2():\n",
        "    # Define the transform for CIFAR-10 dataset\n",
        "    transform_train = transforms.Compose([\n",
        "        transforms.RandomCrop(32, padding=4),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ])\n",
        "    transform_test = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ])\n",
        "\n",
        "    # Load the CIFAR-10 dataset\n",
        "    trainset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
        "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n",
        "    testset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
        "    testloader = torch.utils.data.DataLoader(testset, batch_size=128, shuffle=False, num_workers=2)\n",
        "\n",
        "    # Define the teacher model\n",
        "    teacher_net = models.resnet18(pretrained=True)\n",
        "    num_ftrs = teacher_net.fc.in_features\n",
        "    teacher_net.fc = nn.Linear(num_ftrs, 10)\n",
        "    teacher_net.to(device)\n",
        "\n",
        "    # Define the student model\n",
        "    student_net = resnet18().to(device)\n",
        "    #print(student_net)\n",
        "\n",
        "    # Define the loss function for both teacher and student models\n",
        "    criterion = LabelSmoothingCrossEntropyLoss(smoothing=args.label_smoothing)\n",
        "\n",
        "    # Define the optimizer for both teacher and student models\n",
        "    # teacher_optimizer = optim.Adam(teacher_net.parameters(), lr=0.001)\n",
        "    # student_optimizer = optim.Adam(student_net.parameters(), lr=0.001)\n",
        "    teacher_optimizer =         optimizer = torch.optim.SGD(\n",
        "            [{'params': teacher_net.parameters(), 'initial_lr': args.lr}], lr=args.lr,momentum=args.momentum,weight_decay=args.weight_decay)\n",
        "    student_optimizer =         optimizer = torch.optim.SGD(\n",
        "            [{'params': student_net.parameters(), 'initial_lr': args.lr}], lr=args.lr,momentum=args.momentum,weight_decay=args.weight_decay)\n",
        "\n",
        "    lr_scheduler_teacher = torch.optim.lr_scheduler.CosineAnnealingLR(teacher_optimizer, args.epochs, eta_min = 0, last_epoch=-1)\n",
        "    lr_scheduler_student = torch.optim.lr_scheduler.CosineAnnealingLR(student_optimizer, args.epochs, eta_min = 0, last_epoch=-1)\n",
        "    # Define the temperature parameter for the softmax function\n",
        "    temperature = 3.0\n",
        "\n",
        "    # Define the number of epochs\n",
        "    num_epochs = 50\n",
        "\n",
        "    # Train the student model using distillation\n",
        "    for epoch in range(num_epochs):\n",
        "        running_loss = 0.0\n",
        "        for i, data in enumerate(trainloader, 0):\n",
        "            inputs, labels = data\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            teacher_net.eval()\n",
        "            student_optimizer.zero_grad()\n",
        "            teacher_outputs = teacher_net(inputs)\n",
        "            student_outputs = student_net(inputs)\n",
        "            distillation_loss = distill(teacher_outputs, student_outputs, temperature)\n",
        "            classification_loss = criterion(student_outputs, labels)\n",
        "            loss = distillation_loss + classification_loss\n",
        "            loss.backward()\n",
        "            student_optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "\n",
        "            lr_scheduler_teacher.step()\n",
        "            lr_scheduler_student.step()\n",
        "\n",
        "        print('Epoch %d, Student Loss: %.3f' % (epoch + 1, running_loss / len(trainloader)))\n",
        "\n",
        "    # Evaluate the student model on the test dataset\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for data in testloader:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = student_net(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print('Accuracy of the student network on the 10000 test images: %d %%' % (100 * correct / total))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M5ylgmB9b0TQ"
      },
      "source": [
        "81 - с такими же оптимазерами, лоссом и расписанием, как и на всех экспериментах, 80 имнут"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M47M4gzcUGhR"
      },
      "source": [
        "# Парсим арги"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p8uGcZztUNRj",
        "outputId": "ce74e1e1-5900-42ce-ba6a-ce28823c65c2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "_StoreAction(option_strings=['--path_to_save'], dest='path_to_save', nargs=None, const=None, default='/content/drive/MyDrive/Experiment_Results', type=<class 'str'>, choices=None, required=False, help='s', metavar=None)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "parser = argparse.ArgumentParser(description='Исследование бинарные сетей в PyTorch')\n",
        "\n",
        "parser.add_argument('-j', '--workers', default=2, type=int, metavar='N',\n",
        "                    help='number of data loading workers')\n",
        "parser.add_argument('--epochs', default=50, type=int, metavar='N',\n",
        "                    help='number of total epochs to run')\n",
        "parser.add_argument('--start-epoch', default=0, type=int, metavar='N',\n",
        "                    help='manual epoch number (useful on restarts)')\n",
        "parser.add_argument('-b', '--batch-size', default=128, type=int,\n",
        "                    metavar='N', help='mini-batch size')\n",
        "parser.add_argument('--optimizer', default='sgd', type=str,\n",
        "                    help='which optimizer to use')\n",
        "\n",
        "\n",
        "parser.add_argument('--lr', '--learning-rate', default=0.1, type=float,\n",
        "                    metavar='LR', help='initial learning rate')\n",
        "parser.add_argument('--momentum', default=0.9, type=float, metavar='M',\n",
        "                    help='momentum')\n",
        "parser.add_argument('--weight-decay', '--wd', default=1e-4, type=float,\n",
        "                    metavar='W', help='weight decay')\n",
        "parser.add_argument('--label-smoothing', '--ls', default=0, type=float,\n",
        "                    metavar='LS', help='label smoothing')\n",
        "parser.add_argument('--dropout', default=0.5, type=float,\n",
        "                    help='dropout')\n",
        "parser.add_argument('--stoch_depth', default=0, type=float,\n",
        "                    help='dropout')\n",
        "parser.add_argument('--rand_augment', default=2, type=int,\n",
        "                    help='dropout')\n",
        "\n",
        "parser.add_argument('--binary', default=False, type=bool,\n",
        "                    help='which type of model to use (default: binary is active)')\n",
        "parser.add_argument('--architecture', '--arch', default='mobilenetv2()',\n",
        "                    help='which non bin arch to use (default: cnn_model)')\n",
        "parser.add_argument('--K', default=1, type=int,\n",
        "                    help='how many binarize func to use')\n",
        "\n",
        "\n",
        "parser.add_argument('--pruning', default=False, type=bool,\n",
        "                    help='')\n",
        "parser.add_argument('--type_pruning', default='global', type=str,\n",
        "                    help='')\n",
        "parser.add_argument('--distillation', default=False, type=bool,\n",
        "                    )\n",
        "parser.add_argument('--data_size', default=32, type=int,\n",
        "                    help='Разрешение изображений в датасете для небинарки. Можно варьировать, если хотим ')\n",
        "parser.add_argument('--bin_data_size', default=32, type=int,\n",
        "                    help='Разрешение изображений в датасете для бинарки. Можно варьировать, если хотим ')\n",
        "\n",
        "\n",
        "parser.add_argument('--dataset', '--ds', default='CIFAR10', type=str,\n",
        "                    help='which dataset to use')\n",
        "parser.add_argument('--save_res', default = True, type=bool,\n",
        "                    help='save the results after the launch. (default: while research is underway - False)')\n",
        "parser.add_argument('--path_to_save', default = '/content/drive/MyDrive/Experiment_Results', type=str,\n",
        "                    help='s')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BwN7z5eMTEfy"
      },
      "source": [
        "# Main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ol-Ldv6DQKB"
      },
      "outputs": [],
      "source": [
        "def main():\n",
        "    global args\n",
        "\n",
        "    args, unknown = parser.parse_known_args()\n",
        "    args_list = [(arg, getattr(args, arg)) for arg in vars(args)]\n",
        "\n",
        "    if args.distillation == True:\n",
        "        start = time.time()\n",
        "        destill2()\n",
        "        end = time.time()\n",
        "        print((end-start) / 60)\n",
        "    else:\n",
        "        train_loss_history = []\n",
        "        train_acc_history = []\n",
        "        train_recall_history = []\n",
        "        train_f1_history = []\n",
        "        train_top1_history = []\n",
        "        train_top5_history = []\n",
        "        valid_results = []\n",
        "\n",
        "        times = []\n",
        "\n",
        "        data_size = args.data_size\n",
        "        model = eval(args.architecture)\n",
        "\n",
        "        model.to(device)\n",
        "\n",
        "        #criterion_ce = nn.CrossEntropyLoss(smoothing = args.label_smoothing).to(device)\n",
        "        criterion_ce = LabelSmoothingCrossEntropyLoss(smoothing=args.label_smoothing)\n",
        "\n",
        "\n",
        "        if args.optimizer == 'sgd':\n",
        "            optimizer = torch.optim.SGD(\n",
        "                [{'params': model.parameters(), 'initial_lr': args.lr}], lr=args.lr,momentum=args.momentum,weight_decay=args.weight_decay)\n",
        "        else:\n",
        "            optimizer = torch.optim.Adam(\n",
        "                [{'params': model.parameters, 'initial_lr': args.lr,'weight_decay': args.weight_decay}], lr=args.lr,momentum=args.momentum,weight_decay=args.weight_decay)\n",
        "\n",
        "        lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, args.epochs, eta_min = 0, last_epoch=-1)\n",
        "\n",
        "        normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                        std=[0.229, 0.224, 0.225])\n",
        "\n",
        "        train_loader, val_loader = get_data()\n",
        "\n",
        "        conv_modules = []\n",
        "        for name, module in model.named_modules():\n",
        "            if isinstance(module, nn.Conv2d):\n",
        "                #print(module)\n",
        "                conv_modules.append(module)\n",
        "\n",
        "        for epoch in range(args.start_epoch, args.epochs):\n",
        "\n",
        "            if args.binary == True:\n",
        "                t, k = cpt_tk(epoch)\n",
        "                for module in conv_modules:\n",
        "                    module.k = k.to(device)\n",
        "                    module.t = t.to(device)\n",
        "\n",
        "            start_train_epoch = time.time()\n",
        "\n",
        "            train_loss, train_acc, train_recall, train_f1, train_top1, train_top5 = train(model, train_loader, criterion_ce, optimizer, epoch)\n",
        "            train_loss_history.append(train_loss)\n",
        "            train_acc_history.append(train_acc)\n",
        "            train_recall_history.append(train_recall)\n",
        "            train_f1_history.append(train_f1)\n",
        "            train_top1_history.append(train_top1)\n",
        "            train_top5_history.append(train_top5)\n",
        "\n",
        "            end_train_epoch = time.time()\n",
        "            train_time = end_train_epoch - start_train_epoch\n",
        "            times.append(train_time)\n",
        "\n",
        "            print('Epoch No. {0}. Loss: {1}, Acc: {2}, Recall: {3}, F1: {4}, Top1: {5}, Top5: {6} '.format(epoch+1, train_loss, train_acc, train_recall, train_f1, train_top1, train_top5))\n",
        "            lr_scheduler.step()\n",
        "\n",
        "\n",
        "        valid_results.extend(validate(model, val_loader, criterion_ce))\n",
        "        print('\\nValid results is: Loss: {0}, Acc: {1}, Recall: {2}, F1: {3}, Top1: {4}, Top5: {5} \\n'.format(valid_results[0], valid_results[1], valid_results[2], valid_results[3], valid_results[4], valid_results[5]))\n",
        "\n",
        "\n",
        "        max_train_time = '{:.4f}'.format(max(times))\n",
        "        min_train_time = '{:.4f}'.format(min(times))\n",
        "\n",
        "\n",
        "        summary(model, input_size=(3, 32, 32))\n",
        "\n",
        "\n",
        "\n",
        "        inf = 'Обучение MobileNetV2 на 50и эпохах из библиотеки + LS + WD + RA + DP'\n",
        "        if args.save_res == True:\n",
        "            save_results(args.binary, args_list, train_loss_history, train_acc_history, train_recall_history, train_f1_history, train_top1_history, train_top5_history, valid_results, min_train_time, max_train_time, inf)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RaEibS455knD"
      },
      "source": [
        "# Пуск"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JCKj50LAbY98",
        "outputId": "a6b95652-d120-4742-e75e-c9ae994af285"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ../cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:04<00:00, 34860189.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ../cifar-10-python.tar.gz to ../\n",
            "Files already downloaded and verified\n",
            "Epoch No. 1. Loss: 1.7813, Acc: 0.2726, Recall: 0.2726, F1: 0.2661, Top1: 0.2726, Top5: 0.2726 \n",
            "Epoch No. 2. Loss: 1.5829, Acc: 0.4370, Recall: 0.4370, F1: 0.4316, Top1: 0.4370, Top5: 0.4370 \n",
            "Epoch No. 3. Loss: 0.9720, Acc: 0.5329, Recall: 0.5329, F1: 0.5293, Top1: 0.5329, Top5: 0.5329 \n",
            "Epoch No. 4. Loss: 1.0274, Acc: 0.6043, Recall: 0.6043, F1: 0.6030, Top1: 0.6043, Top5: 0.6043 \n",
            "Epoch No. 5. Loss: 0.9878, Acc: 0.6623, Recall: 0.6623, F1: 0.6613, Top1: 0.6623, Top5: 0.6623 \n",
            "Epoch No. 6. Loss: 0.7551, Acc: 0.6983, Recall: 0.6983, F1: 0.6975, Top1: 0.6983, Top5: 0.6983 \n",
            "Epoch No. 7. Loss: 0.7424, Acc: 0.7307, Recall: 0.7307, F1: 0.7300, Top1: 0.7307, Top5: 0.7307 \n",
            "Epoch No. 8. Loss: 0.5454, Acc: 0.7510, Recall: 0.7510, F1: 0.7505, Top1: 0.7510, Top5: 0.7510 \n",
            "Epoch No. 9. Loss: 0.7195, Acc: 0.7656, Recall: 0.7656, F1: 0.7652, Top1: 0.7656, Top5: 0.7656 \n",
            "Epoch No. 10. Loss: 0.6192, Acc: 0.7860, Recall: 0.7860, F1: 0.7857, Top1: 0.7860, Top5: 0.7860 \n",
            "Epoch No. 11. Loss: 0.6142, Acc: 0.7957, Recall: 0.7957, F1: 0.7954, Top1: 0.7957, Top5: 0.7957 \n",
            "Epoch No. 12. Loss: 0.4993, Acc: 0.8055, Recall: 0.8055, F1: 0.8051, Top1: 0.8055, Top5: 0.8055 \n",
            "Epoch No. 13. Loss: 0.7697, Acc: 0.8169, Recall: 0.8169, F1: 0.8166, Top1: 0.8169, Top5: 0.8169 \n",
            "Epoch No. 14. Loss: 0.5648, Acc: 0.8248, Recall: 0.8248, F1: 0.8245, Top1: 0.8248, Top5: 0.8248 \n",
            "Epoch No. 15. Loss: 0.4410, Acc: 0.8337, Recall: 0.8337, F1: 0.8335, Top1: 0.8337, Top5: 0.8337 \n",
            "Epoch No. 16. Loss: 0.7102, Acc: 0.8375, Recall: 0.8375, F1: 0.8372, Top1: 0.8375, Top5: 0.8375 \n",
            "Epoch No. 17. Loss: 0.4808, Acc: 0.8480, Recall: 0.8480, F1: 0.8478, Top1: 0.8480, Top5: 0.8480 \n",
            "Epoch No. 18. Loss: 0.5116, Acc: 0.8466, Recall: 0.8466, F1: 0.8464, Top1: 0.8466, Top5: 0.8466 \n",
            "Epoch No. 19. Loss: 0.2928, Acc: 0.8582, Recall: 0.8582, F1: 0.8581, Top1: 0.8582, Top5: 0.8582 \n",
            "Epoch No. 20. Loss: 0.3624, Acc: 0.8651, Recall: 0.8651, F1: 0.8649, Top1: 0.8651, Top5: 0.8651 \n",
            "Epoch No. 21. Loss: 0.5746, Acc: 0.8715, Recall: 0.8715, F1: 0.8713, Top1: 0.8715, Top5: 0.8715 \n",
            "Epoch No. 22. Loss: 0.3540, Acc: 0.8754, Recall: 0.8754, F1: 0.8752, Top1: 0.8754, Top5: 0.8754 \n",
            "Epoch No. 23. Loss: 0.4395, Acc: 0.8808, Recall: 0.8808, F1: 0.8807, Top1: 0.8808, Top5: 0.8808 \n",
            "Epoch No. 24. Loss: 0.3098, Acc: 0.8879, Recall: 0.8879, F1: 0.8878, Top1: 0.8879, Top5: 0.8879 \n",
            "Epoch No. 25. Loss: 0.2990, Acc: 0.8924, Recall: 0.8924, F1: 0.8923, Top1: 0.8924, Top5: 0.8924 \n",
            "Epoch No. 26. Loss: 0.3218, Acc: 0.8983, Recall: 0.8983, F1: 0.8983, Top1: 0.8983, Top5: 0.8983 \n",
            "Epoch No. 27. Loss: 0.3108, Acc: 0.9021, Recall: 0.9021, F1: 0.9021, Top1: 0.9021, Top5: 0.9021 \n",
            "Epoch No. 28. Loss: 0.2993, Acc: 0.9100, Recall: 0.9100, F1: 0.9099, Top1: 0.9100, Top5: 0.9100 \n",
            "Epoch No. 29. Loss: 0.2306, Acc: 0.9159, Recall: 0.9159, F1: 0.9159, Top1: 0.9159, Top5: 0.9159 \n",
            "Epoch No. 30. Loss: 0.1793, Acc: 0.9185, Recall: 0.9185, F1: 0.9185, Top1: 0.9185, Top5: 0.9185 \n",
            "Epoch No. 31. Loss: 0.1757, Acc: 0.9227, Recall: 0.9227, F1: 0.9227, Top1: 0.9227, Top5: 0.9227 \n",
            "Epoch No. 32. Loss: 0.3506, Acc: 0.9300, Recall: 0.9300, F1: 0.9300, Top1: 0.9300, Top5: 0.9300 \n",
            "Epoch No. 33. Loss: 0.2006, Acc: 0.9330, Recall: 0.9330, F1: 0.9330, Top1: 0.9330, Top5: 0.9330 \n",
            "Epoch No. 34. Loss: 0.3006, Acc: 0.9392, Recall: 0.9392, F1: 0.9392, Top1: 0.9392, Top5: 0.9392 \n",
            "Epoch No. 35. Loss: 0.2037, Acc: 0.9449, Recall: 0.9449, F1: 0.9449, Top1: 0.9449, Top5: 0.9449 \n",
            "Epoch No. 36. Loss: 0.1498, Acc: 0.9503, Recall: 0.9503, F1: 0.9503, Top1: 0.9503, Top5: 0.9503 \n",
            "Epoch No. 37. Loss: 0.1830, Acc: 0.9519, Recall: 0.9519, F1: 0.9519, Top1: 0.9519, Top5: 0.9519 \n",
            "Epoch No. 38. Loss: 0.1584, Acc: 0.9572, Recall: 0.9572, F1: 0.9572, Top1: 0.9572, Top5: 0.9572 \n",
            "Epoch No. 39. Loss: 0.1816, Acc: 0.9599, Recall: 0.9599, F1: 0.9599, Top1: 0.9599, Top5: 0.9599 \n",
            "Epoch No. 40. Loss: 0.1321, Acc: 0.9631, Recall: 0.9631, F1: 0.9631, Top1: 0.9631, Top5: 0.9631 \n",
            "Epoch No. 41. Loss: 0.1896, Acc: 0.9674, Recall: 0.9674, F1: 0.9674, Top1: 0.9674, Top5: 0.9674 \n",
            "Epoch No. 42. Loss: 0.0957, Acc: 0.9700, Recall: 0.9700, F1: 0.9700, Top1: 0.9700, Top5: 0.9700 \n",
            "Epoch No. 43. Loss: 0.0502, Acc: 0.9717, Recall: 0.9717, F1: 0.9717, Top1: 0.9717, Top5: 0.9717 \n",
            "Epoch No. 44. Loss: 0.1162, Acc: 0.9732, Recall: 0.9732, F1: 0.9732, Top1: 0.9732, Top5: 0.9732 \n",
            "Epoch No. 45. Loss: 0.0730, Acc: 0.9746, Recall: 0.9746, F1: 0.9746, Top1: 0.9746, Top5: 0.9746 \n",
            "Epoch No. 46. Loss: 0.1096, Acc: 0.9753, Recall: 0.9753, F1: 0.9753, Top1: 0.9753, Top5: 0.9753 \n",
            "Epoch No. 47. Loss: 0.0418, Acc: 0.9761, Recall: 0.9761, F1: 0.9761, Top1: 0.9761, Top5: 0.9761 \n",
            "Epoch No. 48. Loss: 0.0608, Acc: 0.9776, Recall: 0.9776, F1: 0.9776, Top1: 0.9776, Top5: 0.9776 \n",
            "Epoch No. 49. Loss: 0.0480, Acc: 0.9773, Recall: 0.9773, F1: 0.9773, Top1: 0.9773, Top5: 0.9773 \n",
            "Epoch No. 50. Loss: 0.0417, Acc: 0.9775, Recall: 0.9775, F1: 0.9775, Top1: 0.9775, Top5: 0.9775 \n",
            "\n",
            "Valid results is: Loss: 0.4809, Acc: 0.9080, Recall: 0.9080, F1: 0.9079, Top1: 0.9080, Top5: 0.9080 \n",
            "\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 32, 32, 32]             864\n",
            "       BatchNorm2d-2           [-1, 32, 32, 32]              64\n",
            "              ReLU-3           [-1, 32, 32, 32]               0\n",
            "            Conv2d-4           [-1, 32, 32, 32]           1,024\n",
            "       BatchNorm2d-5           [-1, 32, 32, 32]              64\n",
            "              ReLU-6           [-1, 32, 32, 32]               0\n",
            "            Conv2d-7           [-1, 32, 32, 32]             288\n",
            "       BatchNorm2d-8           [-1, 32, 32, 32]              64\n",
            "              ReLU-9           [-1, 32, 32, 32]               0\n",
            "           Conv2d-10           [-1, 16, 32, 32]             512\n",
            "      BatchNorm2d-11           [-1, 16, 32, 32]              32\n",
            "           Conv2d-12           [-1, 16, 32, 32]             512\n",
            "      BatchNorm2d-13           [-1, 16, 32, 32]              32\n",
            "             ReLU-14           [-1, 16, 32, 32]               0\n",
            "       Bottleneck-15           [-1, 16, 32, 32]               0\n",
            "           Conv2d-16           [-1, 96, 32, 32]           1,536\n",
            "      BatchNorm2d-17           [-1, 96, 32, 32]             192\n",
            "             ReLU-18           [-1, 96, 32, 32]               0\n",
            "           Conv2d-19           [-1, 96, 32, 32]             864\n",
            "      BatchNorm2d-20           [-1, 96, 32, 32]             192\n",
            "             ReLU-21           [-1, 96, 32, 32]               0\n",
            "           Conv2d-22           [-1, 24, 32, 32]           2,304\n",
            "      BatchNorm2d-23           [-1, 24, 32, 32]              48\n",
            "           Conv2d-24           [-1, 24, 32, 32]             384\n",
            "      BatchNorm2d-25           [-1, 24, 32, 32]              48\n",
            "             ReLU-26           [-1, 24, 32, 32]               0\n",
            "       Bottleneck-27           [-1, 24, 32, 32]               0\n",
            "           Conv2d-28          [-1, 144, 32, 32]           3,456\n",
            "      BatchNorm2d-29          [-1, 144, 32, 32]             288\n",
            "             ReLU-30          [-1, 144, 32, 32]               0\n",
            "           Conv2d-31          [-1, 144, 32, 32]           1,296\n",
            "      BatchNorm2d-32          [-1, 144, 32, 32]             288\n",
            "             ReLU-33          [-1, 144, 32, 32]               0\n",
            "           Conv2d-34           [-1, 24, 32, 32]           3,456\n",
            "      BatchNorm2d-35           [-1, 24, 32, 32]              48\n",
            "             ReLU-36           [-1, 24, 32, 32]               0\n",
            "       Bottleneck-37           [-1, 24, 32, 32]               0\n",
            "           Conv2d-38          [-1, 144, 32, 32]           3,456\n",
            "      BatchNorm2d-39          [-1, 144, 32, 32]             288\n",
            "             ReLU-40          [-1, 144, 32, 32]               0\n",
            "           Conv2d-41          [-1, 144, 16, 16]           1,296\n",
            "      BatchNorm2d-42          [-1, 144, 16, 16]             288\n",
            "             ReLU-43          [-1, 144, 16, 16]               0\n",
            "           Conv2d-44           [-1, 32, 16, 16]           4,608\n",
            "      BatchNorm2d-45           [-1, 32, 16, 16]              64\n",
            "             ReLU-46           [-1, 32, 16, 16]               0\n",
            "       Bottleneck-47           [-1, 32, 16, 16]               0\n",
            "           Conv2d-48          [-1, 192, 16, 16]           6,144\n",
            "      BatchNorm2d-49          [-1, 192, 16, 16]             384\n",
            "             ReLU-50          [-1, 192, 16, 16]               0\n",
            "           Conv2d-51          [-1, 192, 16, 16]           1,728\n",
            "      BatchNorm2d-52          [-1, 192, 16, 16]             384\n",
            "             ReLU-53          [-1, 192, 16, 16]               0\n",
            "           Conv2d-54           [-1, 32, 16, 16]           6,144\n",
            "      BatchNorm2d-55           [-1, 32, 16, 16]              64\n",
            "             ReLU-56           [-1, 32, 16, 16]               0\n",
            "       Bottleneck-57           [-1, 32, 16, 16]               0\n",
            "           Conv2d-58          [-1, 192, 16, 16]           6,144\n",
            "      BatchNorm2d-59          [-1, 192, 16, 16]             384\n",
            "             ReLU-60          [-1, 192, 16, 16]               0\n",
            "           Conv2d-61          [-1, 192, 16, 16]           1,728\n",
            "      BatchNorm2d-62          [-1, 192, 16, 16]             384\n",
            "             ReLU-63          [-1, 192, 16, 16]               0\n",
            "           Conv2d-64           [-1, 32, 16, 16]           6,144\n",
            "      BatchNorm2d-65           [-1, 32, 16, 16]              64\n",
            "             ReLU-66           [-1, 32, 16, 16]               0\n",
            "       Bottleneck-67           [-1, 32, 16, 16]               0\n",
            "           Conv2d-68          [-1, 192, 16, 16]           6,144\n",
            "      BatchNorm2d-69          [-1, 192, 16, 16]             384\n",
            "             ReLU-70          [-1, 192, 16, 16]               0\n",
            "           Conv2d-71            [-1, 192, 8, 8]           1,728\n",
            "      BatchNorm2d-72            [-1, 192, 8, 8]             384\n",
            "             ReLU-73            [-1, 192, 8, 8]               0\n",
            "           Conv2d-74             [-1, 64, 8, 8]          12,288\n",
            "      BatchNorm2d-75             [-1, 64, 8, 8]             128\n",
            "             ReLU-76             [-1, 64, 8, 8]               0\n",
            "       Bottleneck-77             [-1, 64, 8, 8]               0\n",
            "           Conv2d-78            [-1, 384, 8, 8]          24,576\n",
            "      BatchNorm2d-79            [-1, 384, 8, 8]             768\n",
            "             ReLU-80            [-1, 384, 8, 8]               0\n",
            "           Conv2d-81            [-1, 384, 8, 8]           3,456\n",
            "      BatchNorm2d-82            [-1, 384, 8, 8]             768\n",
            "             ReLU-83            [-1, 384, 8, 8]               0\n",
            "           Conv2d-84             [-1, 64, 8, 8]          24,576\n",
            "      BatchNorm2d-85             [-1, 64, 8, 8]             128\n",
            "             ReLU-86             [-1, 64, 8, 8]               0\n",
            "       Bottleneck-87             [-1, 64, 8, 8]               0\n",
            "           Conv2d-88            [-1, 384, 8, 8]          24,576\n",
            "      BatchNorm2d-89            [-1, 384, 8, 8]             768\n",
            "             ReLU-90            [-1, 384, 8, 8]               0\n",
            "           Conv2d-91            [-1, 384, 8, 8]           3,456\n",
            "      BatchNorm2d-92            [-1, 384, 8, 8]             768\n",
            "             ReLU-93            [-1, 384, 8, 8]               0\n",
            "           Conv2d-94             [-1, 64, 8, 8]          24,576\n",
            "      BatchNorm2d-95             [-1, 64, 8, 8]             128\n",
            "             ReLU-96             [-1, 64, 8, 8]               0\n",
            "       Bottleneck-97             [-1, 64, 8, 8]               0\n",
            "           Conv2d-98            [-1, 384, 8, 8]          24,576\n",
            "      BatchNorm2d-99            [-1, 384, 8, 8]             768\n",
            "            ReLU-100            [-1, 384, 8, 8]               0\n",
            "          Conv2d-101            [-1, 384, 8, 8]           3,456\n",
            "     BatchNorm2d-102            [-1, 384, 8, 8]             768\n",
            "            ReLU-103            [-1, 384, 8, 8]               0\n",
            "          Conv2d-104             [-1, 64, 8, 8]          24,576\n",
            "     BatchNorm2d-105             [-1, 64, 8, 8]             128\n",
            "            ReLU-106             [-1, 64, 8, 8]               0\n",
            "      Bottleneck-107             [-1, 64, 8, 8]               0\n",
            "          Conv2d-108            [-1, 384, 8, 8]          24,576\n",
            "     BatchNorm2d-109            [-1, 384, 8, 8]             768\n",
            "            ReLU-110            [-1, 384, 8, 8]               0\n",
            "          Conv2d-111            [-1, 384, 8, 8]           3,456\n",
            "     BatchNorm2d-112            [-1, 384, 8, 8]             768\n",
            "            ReLU-113            [-1, 384, 8, 8]               0\n",
            "          Conv2d-114             [-1, 96, 8, 8]          36,864\n",
            "     BatchNorm2d-115             [-1, 96, 8, 8]             192\n",
            "          Conv2d-116             [-1, 96, 8, 8]           6,144\n",
            "     BatchNorm2d-117             [-1, 96, 8, 8]             192\n",
            "            ReLU-118             [-1, 96, 8, 8]               0\n",
            "      Bottleneck-119             [-1, 96, 8, 8]               0\n",
            "          Conv2d-120            [-1, 576, 8, 8]          55,296\n",
            "     BatchNorm2d-121            [-1, 576, 8, 8]           1,152\n",
            "            ReLU-122            [-1, 576, 8, 8]               0\n",
            "          Conv2d-123            [-1, 576, 8, 8]           5,184\n",
            "     BatchNorm2d-124            [-1, 576, 8, 8]           1,152\n",
            "            ReLU-125            [-1, 576, 8, 8]               0\n",
            "          Conv2d-126             [-1, 96, 8, 8]          55,296\n",
            "     BatchNorm2d-127             [-1, 96, 8, 8]             192\n",
            "            ReLU-128             [-1, 96, 8, 8]               0\n",
            "      Bottleneck-129             [-1, 96, 8, 8]               0\n",
            "          Conv2d-130            [-1, 576, 8, 8]          55,296\n",
            "     BatchNorm2d-131            [-1, 576, 8, 8]           1,152\n",
            "            ReLU-132            [-1, 576, 8, 8]               0\n",
            "          Conv2d-133            [-1, 576, 8, 8]           5,184\n",
            "     BatchNorm2d-134            [-1, 576, 8, 8]           1,152\n",
            "            ReLU-135            [-1, 576, 8, 8]               0\n",
            "          Conv2d-136             [-1, 96, 8, 8]          55,296\n",
            "     BatchNorm2d-137             [-1, 96, 8, 8]             192\n",
            "            ReLU-138             [-1, 96, 8, 8]               0\n",
            "      Bottleneck-139             [-1, 96, 8, 8]               0\n",
            "          Conv2d-140            [-1, 576, 8, 8]          55,296\n",
            "     BatchNorm2d-141            [-1, 576, 8, 8]           1,152\n",
            "            ReLU-142            [-1, 576, 8, 8]               0\n",
            "          Conv2d-143            [-1, 576, 4, 4]           5,184\n",
            "     BatchNorm2d-144            [-1, 576, 4, 4]           1,152\n",
            "            ReLU-145            [-1, 576, 4, 4]               0\n",
            "          Conv2d-146            [-1, 160, 4, 4]          92,160\n",
            "     BatchNorm2d-147            [-1, 160, 4, 4]             320\n",
            "            ReLU-148            [-1, 160, 4, 4]               0\n",
            "      Bottleneck-149            [-1, 160, 4, 4]               0\n",
            "          Conv2d-150            [-1, 960, 4, 4]         153,600\n",
            "     BatchNorm2d-151            [-1, 960, 4, 4]           1,920\n",
            "            ReLU-152            [-1, 960, 4, 4]               0\n",
            "          Conv2d-153            [-1, 960, 4, 4]           8,640\n",
            "     BatchNorm2d-154            [-1, 960, 4, 4]           1,920\n",
            "            ReLU-155            [-1, 960, 4, 4]               0\n",
            "          Conv2d-156            [-1, 160, 4, 4]         153,600\n",
            "     BatchNorm2d-157            [-1, 160, 4, 4]             320\n",
            "            ReLU-158            [-1, 160, 4, 4]               0\n",
            "      Bottleneck-159            [-1, 160, 4, 4]               0\n",
            "          Conv2d-160            [-1, 960, 4, 4]         153,600\n",
            "     BatchNorm2d-161            [-1, 960, 4, 4]           1,920\n",
            "            ReLU-162            [-1, 960, 4, 4]               0\n",
            "          Conv2d-163            [-1, 960, 4, 4]           8,640\n",
            "     BatchNorm2d-164            [-1, 960, 4, 4]           1,920\n",
            "            ReLU-165            [-1, 960, 4, 4]               0\n",
            "          Conv2d-166            [-1, 160, 4, 4]         153,600\n",
            "     BatchNorm2d-167            [-1, 160, 4, 4]             320\n",
            "            ReLU-168            [-1, 160, 4, 4]               0\n",
            "      Bottleneck-169            [-1, 160, 4, 4]               0\n",
            "          Conv2d-170            [-1, 960, 4, 4]         153,600\n",
            "     BatchNorm2d-171            [-1, 960, 4, 4]           1,920\n",
            "            ReLU-172            [-1, 960, 4, 4]               0\n",
            "          Conv2d-173            [-1, 960, 4, 4]           8,640\n",
            "     BatchNorm2d-174            [-1, 960, 4, 4]           1,920\n",
            "            ReLU-175            [-1, 960, 4, 4]               0\n",
            "          Conv2d-176            [-1, 320, 4, 4]         307,200\n",
            "     BatchNorm2d-177            [-1, 320, 4, 4]             640\n",
            "          Conv2d-178            [-1, 320, 4, 4]          51,200\n",
            "     BatchNorm2d-179            [-1, 320, 4, 4]             640\n",
            "            ReLU-180            [-1, 320, 4, 4]               0\n",
            "      Bottleneck-181            [-1, 320, 4, 4]               0\n",
            "          Conv2d-182           [-1, 1280, 4, 4]       3,686,400\n",
            "     BatchNorm2d-183           [-1, 1280, 4, 4]           2,560\n",
            "            ReLU-184           [-1, 1280, 4, 4]               0\n",
            "AdaptiveAvgPool2d-185           [-1, 1280, 1, 1]               0\n",
            "         Dropout-186                 [-1, 1280]               0\n",
            "          Linear-187                   [-1, 10]          12,810\n",
            "================================================================\n",
            "Total params: 5,573,722\n",
            "Trainable params: 5,573,722\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 40.15\n",
            "Params size (MB): 21.26\n",
            "Estimated Total Size (MB): 61.43\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "if __name__ == '__main__' :\n",
        "    main()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "3oRDXABJRPSf",
        "eNgVsCksRTSj",
        "_k6wsJ_mipKJ",
        "uDCc5rVrSSZ1",
        "GOGfiSx0ihVl",
        "x3_maKujrEmM",
        "V8V_ix_oEM7n"
      ],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}